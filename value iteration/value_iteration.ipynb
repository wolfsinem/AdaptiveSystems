{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit94409e1e4df94da1b5cc700cc0e6ab29",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Value Iteration - Implementation\n",
    "\n",
    "Value iteration is a method of computing an optimal MDP policy and its value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "source": [
    "#### Initialise parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD = -0.1\n",
    "GAMMA = 0.7\n",
    "DISCOUNT = 0.99 \n",
    "\n",
    "ACTIONS = [(1, 0), (0, -1), (-1, 0), (0, 1)]  # actions which can be D, L, U, R\n",
    "NUM_ACTIONS = len(ACTIONS)\n",
    "\n",
    "# Grid size based on amount of rows and columns\n",
    "ROW = 4\n",
    "COL = 4\n",
    "\n",
    "# Grid with terminal states\n",
    "u = [[0, 0, 0, 40],\n",
    "     [0, 0, 0, 0],\n",
    "     [0, 0, 0, 0],\n",
    "     [10, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maze_grid(arr, policy=False):\n",
    "    \"\"\"This function initializes the maze grid with all of the \n",
    "    given rewards per state and prints it out nicely.    \n",
    "    The grid has 4 rows and 4 columns which is set in the cell above.\n",
    "    \"\"\"\n",
    "    res = \"\"\n",
    "    for r in range(ROW):\n",
    "        res += \"|\"\n",
    "        for c in range(COL):\n",
    "            if r == 0 and c == 3:\n",
    "                val = '\\u2610'\n",
    "            elif r == 3 and c == 0:\n",
    "                val = '\\u2610'\n",
    "            elif r == 3 and c == 2:\n",
    "                val += \" S\"\n",
    "            else:\n",
    "                if policy:\n",
    "                    val = ['\\u2193', '\\u2190', '\\u2191', '\\u2192'][arr[r][c]] # DOWN/LEFT/UP/RIGHT\n",
    "                else:\n",
    "                    val = str(arr[r][c])\n",
    "            res += \" \" + val[:5].ljust(5) + \" |\" \n",
    "        res += \"\\n\"\n",
    "    print(res)"
   ]
  },
  {
   "source": [
    "#### 'Visualize' the maze grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| 0     | 0     | 0     | ☐     |\n| 0     | 0     | 0     | 0     |\n| 0     | 0     | 0     | 0     |\n| ☐     | 0     | 0 S   | 0     |\n\n"
     ]
    }
   ],
   "source": [
    "maze_grid(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility(rewards, r, c, action):\n",
    "    \"\"\"This function gets the utility of the state reached \n",
    "    by performing the given action from the given state\n",
    "    \"\"\"\n",
    "    dr, dc = ACTIONS[action]\n",
    "    newR = r + dr\n",
    "    newC = c + dc\n",
    "    if newR < 0 or newC < 0 or newR >= ROW or newC >= COL or (newR == 3 and newC == 2): \n",
    "        return rewards[r][c]\n",
    "    else:\n",
    "        return rewards[newR][newC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_utility(rewards, r, c, action):\n",
    "    \"\"\"This function calculates the utility of a state given \n",
    "    an action\n",
    "    \"\"\"\n",
    "    if r == 3 and c == 1:\n",
    "        u = -2\n",
    "    elif r == 1 and c == 2:\n",
    "        u = -10\n",
    "    elif r == 1 and c == 3:\n",
    "        u = -10\n",
    "    else:\n",
    "        u = REWARD\n",
    "                \n",
    "    u += 0.1 * GAMMA * get_utility(rewards, r, c, (action-1)%4)\n",
    "    u += 0.7 * GAMMA * get_utility(rewards, r, c, action)\n",
    "    u += 0.1 * GAMMA * get_utility(rewards, r, c, (action+1)%4)\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(rewards):\n",
    "    \"\"\"This function initializes the maze grid with all of the \n",
    "    given rewards per state and prints it out nicely.    \n",
    "    The grid has 4 rows and 4 columns which is set in the cell above.\n",
    "    \"\"\"\n",
    "    print(\"During the value iteration:\\n\")\n",
    "    while True:\n",
    "        next_utility = [[0, 0, 0, 40],\n",
    "                        [0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0],\n",
    "                        [10, 0, 0, 0]]\n",
    "        error = 0\n",
    "        for r in range(ROW):\n",
    "            for c in range(COL):\n",
    "                if (r == 0 and c == 3) or (r == 3 and c == 0) or (r == 3 and c == 1):\n",
    "                    continue\n",
    "                next_utility[r][c] = max([calculate_utility(rewards, r, c, action) for action in range(NUM_ACTIONS)]) # Bellman update\n",
    "                error = max(error, abs(next_utility[r][c]-rewards[r][c]))\n",
    "        rewards = next_utility\n",
    "        maze_grid(rewards)\n",
    "        if error < ((1-GAMMA) / GAMMA):\n",
    "            break\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy(rewards):\n",
    "    \"\"\"This function gets the optimal policy from U\n",
    "    \"\"\"\n",
    "    policy = [[-1,-1,-1,40],\n",
    "              [-1,-1,-10,-10],\n",
    "              [-1,-1,-1,-1],\n",
    "              [10,-2,-1,-1]]\n",
    "\n",
    "    for r in range(ROW):\n",
    "        for c in range(COL):\n",
    "            if (r == 0 and c == 3) or (r == 3 and c == 0) or (r == 3 and c == 1):\n",
    "                continue\n",
    "            # Choose the action that maximizes the utility\n",
    "            maxAction, maxU = None, -float(\"inf\")\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                u = calculate_utility(rewards, r, c, action)\n",
    "                if u > maxU:\n",
    "                    maxAction, maxU = action, u\n",
    "                    print(\"MA {}\".format(maxAction))\n",
    "                    print(\"MU {}\".format(maxU))\n",
    "            policy[r][c] = maxAction\n",
    "    return policy"
   ]
  },
  {
   "source": [
    "#### Print optimal policy "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The initial maze grid is:\n\n| 0     | 0     | 0     | ☐     |\n| 0     | 0     | 0     | 0     |\n| 0     | 0     | 0     | 0     |\n| ☐     | 0     | 0 S   | 0     |\n\nDuring the value iteration:\n\n| -0.1  | -0.1  | 19.49 | ☐     |\n| -0.1  | -0.1  | -10.0 | 9.599 |\n| 4.8   | -0.1  | -0.1  | -0.1  |\n| ☐     | 2.899 | 2.899 | -0.1  |\n\n| -0.16 | 9.440 | 20.16 | ☐     |\n| 2.237 | -0.16 | 0.219 | 9.572 |\n| 2.923 | 2.447 | -0.16 | 4.589 |\n| ☐     | 0.890 | 0.890 | -0.16 |\n\n| 4.671 | 10.43 | 20.92 | ☐     |\n| 1.478 | 4.698 | 0.539 | 10.28 |\n| 1.900 | 1.383 | 2.153 | 4.900 |\n| ☐     | -0.14 | -0.14 | 2.126 |\n\n| 5.441 | 11.21 | 21.00 | ☐     |\n| 2.662 | 5.152 | 1.303 | 10.35 |\n| 1.091 | 2.485 | 2.489 | 5.433 |\n| ☐     | -0.95 | -0.95 | 2.598 |\n\n| 5.961 | 11.33 | 21.06 | ☐     |\n| 3.113 | 5.672 | 1.376 | 10.41 |\n| 1.454 | 2.675 | 2.827 | 5.529 |\n| ☐     | -0.76 | -0.76 | 2.926 |\n\n| 6.090 | 11.41 | 21.07 | ☐     |\n| 3.436 | 5.769 | 1.446 | 10.42 |\n| 1.714 | 2.979 | 2.904 | 5.589 |\n| ☐     | -0.70 | -0.70 | 3.019 |\n\nRewards: [[6.090311308369998, 11.410708676249996, 21.07068698318, 40], [3.4362059861099983, 5.769380715659998, 1.4462658615899961, 10.425526945249997], [1.714586168919999, 2.979090421189998, 2.9040038402499984, 5.589015688719998], [0.6017235335599992, -0.7003182929700014, 0, 3.0193389952199983]] \n\nMA 0\nMU 2.808812332117298\nMA 1\nMU 3.551108751714898\nMA 2\nMU 4.109323940024698\nMA 3\nMU 6.158103461976097\nMA 0\nMU 4.628266431081898\nMA 2\nMU 7.3925171317709975\nMA 3\nMU 11.4272428791919\nMA 0\nMU 4.207419879516597\nMA 1\nMU 7.067433950496397\nMA 2\nMU 13.8233862290957\nMA 3\nMU 21.076186699133896\nMA 0\nMU 1.3845382918946991\nMA 1\nMU 2.1300837566041984\nMA 2\nMU 3.528643610225198\nMA 0\nMU 1.7015273357220984\nMA 1\nMU 2.5910268700146983\nMA 2\nMU 5.833020280701497\nMA 0\nMU -7.443394582013802\nMA 1\nMU -5.494775091686503\nMA 2\nMU 1.4582801580218985\nMA 0\nMU -6.430356816048403\nMA 1\nMU -6.100098629610502\nMA 2\nMU 10.431025496478798\nMA 0\nMU 0.5234018927520993\nMA 1\nMU 1.0228022891476993\nMA 2\nMU 1.9122982945015985\nMA 0\nMU -0.11985466291340087\nMA 1\nMU 1.094981592359099\nMA 2\nMU 3.0502978513152983\nMA 0\nMU 1.9227293094161986\nMA 3\nMU 2.943136566601598\nMA 0\nMU 1.9739874746856987\nMA 1\nMU 2.2641024975553985\nMA 2\nMU 5.603019570200398\nMA 0\nMU 0.06233144915749977\nMA 2\nMU 1.4852933308799987\nMA 3\nMU 1.5827563764752988\nMA 0\nMU 1.8021835669885986\nMA 1\nMU 1.9820609355335987\nMA 2\nMU 3.0613251468035987\nThe optimal policy is:\n\n| →     | →     | →     | ☐     |\n| ↑     | ↑     | ↑     | ↑     |\n| ↑     | ↑     | →     | ↑     |\n| ☐     | ↑     | ↑ S   | ↑     |\n\n"
     ]
    }
   ],
   "source": [
    "# Print the initial environment\n",
    "print(\"The initial maze grid is:\\n\")\n",
    "maze_grid(u)\n",
    "\n",
    "# Value iteration\n",
    "rewards = value_iteration(u)\n",
    "print('Rewards: {} \\n'.format(rewards))\n",
    "\n",
    "# Get the optimal policy from U and print it\n",
    "policy = optimal_policy(rewards)\n",
    "print(\"The optimal policy is:\\n\")\n",
    "maze_grid(policy, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}