{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit94409e1e4df94da1b5cc700cc0e6ab29",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Value Iteration - Implementation\n",
    "\n",
    "Value iteration is a method of computing an optimal MDP policy and its value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "source": [
    "#### Initialise parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD = -1\n",
    "GAMMA = 0.9\n",
    "\n",
    "ACTIONS = [(1, 0), (0, -1), (-1, 0), (0, 1)]  # actions which can be D, L, U, R\n",
    "NUM_ACTIONS = len(ACTIONS)\n",
    "\n",
    "# Grid size based on amount of rows and columns\n",
    "ROW = 4\n",
    "COL = 4\n",
    "\n",
    "# Grid with all of the rewards\n",
    "rewards = [[-1, -1, -1, 40],\n",
    "    [-1, -1, -10, -10],\n",
    "    [-1, -1, -1, -1],\n",
    "    [10, -2, -1, -1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maze_grid(arr, policy=False):\n",
    "    \"\"\"This function initializes the maze grid with all of the \n",
    "    given rewards per state and prints it out nicely.    \n",
    "    The grid has 4 rows and 4 columns which is set in the cell above.\n",
    "\n",
    "    Args:\n",
    "        arr::[int]\n",
    "            Multidimensional grid with rewards per state\n",
    "    \n",
    "    Returns:\n",
    "        res::int\n",
    "            Prints out the result\n",
    "    \"\"\"\n",
    "    res = \"\"\n",
    "    for r in range(ROW):\n",
    "        res += \"|\"\n",
    "        for c in range(COL):\n",
    "            if policy:\n",
    "                val = ['\\u2193', '\\u2190', '\\u2191', '\\u2192'][arr[r][c]] # arrow symbols\n",
    "            else:\n",
    "                val = str(arr[r][c])\n",
    "            res += \" \" + val[:5].ljust(5) + \" |\" \n",
    "        res += \"\\n\"\n",
    "    print(res)"
   ]
  },
  {
   "source": [
    "#### 'Visualize' the maze grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| -1    | -1    | -1    | 40    |\n| -1    | -1    | -10   | -10   |\n| -1    | -1    | -1    | -1    |\n| 10    | -2    | -1    | -1    |\n\n"
     ]
    }
   ],
   "source": [
    "maze_grid(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getU(rewards, r, c, action):\n",
    "    \"\"\"This function gets the utility of the state reached \n",
    "    by performing the given action from the given state\n",
    "\n",
    "    Args:\n",
    "        rewards::[int]\n",
    "            Utility \n",
    "        r::[int]\n",
    "            row         \n",
    "        c::[int]\n",
    "            column\n",
    "        action::[int]\n",
    "            \n",
    "    Returns:\n",
    "        U[newR][newC]::int\n",
    "    \"\"\"\n",
    "    dr, dc = ACTIONS[action]\n",
    "    newR, newC = r+dr, c+dc\n",
    "    if newR < 0 or newC < 0 or newR >= ROW or newC >= COL or (newR == newC == 1):\n",
    "        return rewards[r][c]\n",
    "    else:\n",
    "        return rewards[newR][newC]\n",
    "\n",
    "\n",
    "def calculateU(rewards, r, c, action):\n",
    "    \"\"\"This function calculates the utility of a state given \n",
    "    an action\n",
    "\n",
    "    Args:\n",
    "        rewards::[int]\n",
    "            Utility\n",
    "        r::[int]\n",
    "            Row          \n",
    "        c::[int]\n",
    "            Column\n",
    "        action::[int]\n",
    "            Action\n",
    "    Returns:\n",
    "        u::int\n",
    "            Utility\n",
    "    \"\"\"\n",
    "    u = REWARD\n",
    "    u += 0.1 * GAMMA * getU(rewards, r, c, (action-1)%4)\n",
    "    u += 0.8 * GAMMA * getU(rewards, r, c, action)\n",
    "    u += 0.1 * GAMMA * getU(rewards, r, c, (action+1)%4)\n",
    "    return u\n",
    "\n",
    "def valueIteration(rewards):\n",
    "    \"\"\"This function initializes the maze grid with all of the \n",
    "    given rewards per state and prints it out nicely.    \n",
    "    The grid has 4 rows and 4 columns which is set in the cell above.\n",
    "\n",
    "    Args:\n",
    "        rewards::[int]\n",
    "            Multidimensional grid with rewards per state\n",
    "    \n",
    "    Returns:\n",
    "        rewards::int\n",
    "            Prints out the result\n",
    "    \"\"\"\n",
    "    print(\"During the value iteration:\\n\")\n",
    "    while True:\n",
    "        nextU = [[0, 0, 0, 1], [0, 0, 0, -1], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "        error = 0\n",
    "        for r in range(ROW):\n",
    "            for c in range(COL):\n",
    "                if (r <= 1 and c == 3) or (r == c == 1):\n",
    "                    continue\n",
    "                nextU[r][c] = max([calculateU(rewards, r, c, action) for action in range(NUM_ACTIONS)]) # Bellman update\n",
    "                error = max(error, abs(nextU[r][c]-rewards[r][c]))\n",
    "        rewards = nextU\n",
    "        maze_grid(rewards)\n",
    "        if error < ((1-GAMMA) / GAMMA):\n",
    "            break\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def getOptimalPolicy(rewards):\n",
    "    \"\"\"This function gets the optimal policy from U\n",
    "\n",
    "    Args:\n",
    "        rewards::[int]\n",
    "            Multidimensional grid with rewards per state\n",
    "    \n",
    "    Returns:\n",
    "        policy::int\n",
    "            returns the optimal policy\n",
    "    \"\"\"\n",
    "    policy = [[-1, -1, -1, -1] for i in range(ROW)]\n",
    "    for r in range(ROW):\n",
    "        for c in range(COL):\n",
    "            if (r <= 1 and c == 3) or (r == c == 1):\n",
    "                continue\n",
    "            # Choose the action that maximizes the utility\n",
    "            maxAction, maxU = None, -float(\"inf\")\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                u = calculateU(rewards, r, c, action)\n",
    "                if u > maxU:\n",
    "                    maxAction, maxU = action, u\n",
    "            policy[r][c] = maxAction\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The initial maze grid is:\n\n| -1    | -1    | -1    | 40    |\n| -1    | -1    | -10   | -10   |\n| -1    | -1    | -1    | -1    |\n| 10    | -2    | -1    | -1    |\n\nDuring the value iteration:\n\n| -1.90 | -1.90 | 26.81 | 1     |\n| -1.90 | 0     | -3.52 | -1    |\n| 6.020 | -1.90 | -1.90 | -1.90 |\n| 7.010 | 5.930 | -1.90 | -1.90 |\n\n| -2.71 | 17.96 | 18.22 | 1     |\n| 2.992 | 0     | 17.89 | -1    |\n| 4.418 | 3.697 | -2.71 | -2.06 |\n| 5.219 | 4.409 | 2.927 | -2.71 |\n\n| 11.95 | 15.35 | 15.18 | 1     |\n| 2.719 | 0     | 13.64 | -1    |\n| 3.488 | 2.910 | 12.03 | -2.14 |\n| 3.625 | 3.487 | 2.194 | 0.678 |\n\n| 11.37 | 12.69 | 12.64 | 1     |\n| 8.098 | 0     | 11.27 | -1    |\n| 2.186 | 8.239 | 8.889 | 7.634 |\n| 2.250 | 2.186 | 8.038 | 0.447 |\n\n| 9.893 | 10.39 | 10.29 | 1     |\n| 8.647 | 0     | 9.053 | -1    |\n| 5.863 | 6.338 | 8.543 | 5.350 |\n| 1.019 | 5.858 | 5.637 | 5.515 |\n\n| 8.150 | 8.298 | 8.223 | 1     |\n| 7.679 | 0     | 7.213 | -1    |\n| 6.324 | 6.249 | 6.570 | 5.557 |\n| 3.840 | 4.163 | 6.174 | 4.037 |\n\n| 6.399 | 6.448 | 6.364 | 1     |\n| 6.250 | 0     | 5.525 | -1    |\n| 5.661 | 4.667 | 5.256 | 4.004 |\n| 4.274 | 4.400 | 4.468 | 4.309 |\n\n| 4.781 | 4.792 | 4.713 | 1     |\n| 4.733 | 0     | 4.024 | -1    |\n| 4.430 | 3.892 | 3.758 | 3.082 |\n| 3.856 | 3.147 | 3.568 | 2.965 |\n\n| 3.306 | 3.305 | 3.236 | 1     |\n| 3.294 | 0     | 2.665 | -1    |\n| 3.156 | 2.823 | 2.525 | 1.883 |\n| 2.820 | 2.470 | 2.256 | 2.113 |\n\n| 1.975 | 1.975 | 1.911 | 1     |\n| 1.973 | 0     | 1.480 | -1    |\n| 1.910 | 1.749 | 1.475 | 0.918 |\n| 1.749 | 1.506 | 1.230 | 0.984 |\n\n| 0.778 | 0.778 | 0.727 | 1     |\n| 0.777 | 0     | 0.419 | -1    |\n| 0.750 | 0.668 | 0.503 | 0.061 |\n| 0.668 | 0.552 | 0.328 | 0.057 |\n\n| -0.29 | -0.29 | -0.17 | 1     |\n| -0.29 | 0     | -0.52 | -1    |\n| -0.31 | -0.34 | -0.45 | -0.72 |\n| -0.34 | -0.40 | -0.52 | -0.75 |\n\n| -1.26 | -1.18 | -0.34 | 1     |\n| -1.26 | 0     | -1.26 | -1    |\n| -1.27 | -1.29 | -1.34 | -1.48 |\n| -1.29 | -1.32 | -1.38 | -1.51 |\n\n| -2.07 | -1.45 | -0.42 | 1     |\n| -2.14 | 0     | -1.45 | -1    |\n| -2.14 | -2.15 | -2.16 | -1.97 |\n| -2.15 | -2.16 | -2.19 | -2.26 |\n\n| -2.43 | -1.56 | -0.44 | 1     |\n| -2.88 | 0     | -1.52 | -1    |\n| -2.92 | -2.93 | -2.41 | -2.09 |\n| -2.93 | -2.93 | -2.95 | -2.82 |\n\n| -2.60 | -1.60 | -0.45 | 1     |\n| -3.26 | 0     | -1.55 | -1    |\n| -3.60 | -3.26 | -2.55 | -2.12 |\n| -3.63 | -3.64 | -3.25 | -3.02 |\n\n| -2.68 | -1.61 | -0.46 | 1     |\n| -3.46 | 0     | -1.55 | -1    |\n| -3.97 | -3.45 | -2.60 | -2.14 |\n| -4.24 | -3.96 | -3.43 | -3.09 |\n\n| -2.71 | -1.62 | -0.46 | 1     |\n| -3.55 | 0     | -1.56 | -1    |\n| -4.16 | -3.54 | -2.62 | -2.14 |\n| -4.59 | -4.14 | -3.50 | -3.12 |\n\n| -2.73 | -1.62 | -0.46 | 1     |\n| -3.59 | 0     | -1.56 | -1    |\n| -4.25 | -3.58 | -2.63 | -2.14 |\n| -4.77 | -4.21 | -3.54 | -3.14 |\n\n| -2.73 | -1.62 | -0.46 | 1     |\n| -3.61 | 0     | -1.56 | -1    |\n| -4.29 | -3.60 | -2.64 | -2.15 |\n| -4.84 | -4.25 | -3.56 | -3.14 |\n\nThe optimal policy is:\n\n| →     | →     | →     | →     |\n| ↑     | →     | ↑     | →     |\n| ↑     | →     | ↑     | ↑     |\n| →     | →     | ↑     | ↑     |\n\n"
     ]
    }
   ],
   "source": [
    "# Print the initial environment\n",
    "print(\"The initial maze grid is:\\n\")\n",
    "maze_grid(rewards)\n",
    "\n",
    "# Value iteration\n",
    "rewards = valueIteration(rewards)\n",
    "\n",
    "# Get the optimal policy from U and print it\n",
    "policy = getOptimalPolicy(rewards)\n",
    "print(\"The optimal policy is:\\n\")\n",
    "maze_grid(policy, True)"
   ]
  }
 ]
}